# -*- coding: utf-8 -*-
"""DataProcessingandCleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6uPY9QBfElRXrho2rwVEjTbn-IYspBj
"""

import pandas as pd

# Read all CSV file into a DataFrame

df2008 = pd.read_csv("/content/Crime_Incidents_in_2008.csv")
df2009 = pd.read_csv("/content/Crime_Incidents_in_2009.csv")
df2010 = pd.read_csv("/content/Crime_Incidents_in_2010.csv")
df2011 = pd.read_csv("/content/Crime_Incidents_in_2011.csv")
df2012 = pd.read_csv("/content/Crime_Incidents_in_2012.csv")
df2013 = pd.read_csv("/content/Crime_Incidents_in_2013.csv")
df2014 = pd.read_csv("/content/Crime_Incidents_in_2014.csv")
df2015 = pd.read_csv("/content/Crime_Incidents_in_2015.csv")
df2016 = pd.read_csv("/content/Crime_Incidents_in_2016.csv")
df2017 = pd.read_csv("/content/Crime_Incidents_in_2017.csv")
df2018 = pd.read_csv("/content/Crime_Incidents_in_2018.csv")
df2019 = pd.read_csv("/content/Crime_Incidents_in_2019.csv")
df2020 = pd.read_csv("/content/Crime_Incidents_in_2020.csv")
df2021 = pd.read_csv("/content/Crime_Incidents_in_2021.csv")
df2022 = pd.read_csv("/content/Crime_Incidents_in_2022.csv")
df2023 = pd.read_csv("/content/Crime_Incidents_in_2023.csv")

# Storing column names of all the dataframes

columns2008 = set(df2008.columns)
columns2009 = set(df2009.columns)
columns2010 = set(df2010.columns)
columns2011 = set(df2011.columns)
columns2012 = set(df2012.columns)
columns2013 = set(df2013.columns)
columns2014 = set(df2014.columns)
columns2015 = set(df2015.columns)
columns2016 = set(df2016.columns)
columns2017 = set(df2017.columns)
columns2018 = set(df2018.columns)
columns2019 = set(df2019.columns)
columns2020 = set(df2020.columns)
columns2021 = set(df2021.columns)
columns2022 = set(df2022.columns)
columns2023 = set(df2023.columns)

# Printing the column names to compare before merging the datasets

print(columns2008)
print(columns2009)
print(columns2010)
print(columns2011)
print(columns2012)
print(columns2013)
print(columns2014)
print(columns2015)
print(columns2016)
print(columns2017)
print(columns2018)
print(columns2019)
print(columns2020)
print(columns2021)
print(columns2022)
print(columns2023)

# List of dataframes from 2008 to 2023 and concat them

frames = [df2008, df2009, df2010, df2011, df2012, df2013, df2014, df2015, df2016, df2017, df2018, df2019, df2020, df2021, df2022, df2023]

df_combine = pd.concat(frames)

print(df_combine)

print(df_combine.info())

# Subset of the combined dataframe with only geographical info.

df_location_geog = df_combine[["BLOCK", "XBLOCK", "YBLOCK", "WARD", "ANC", "DISTRICT", "PSA", "NEIGHBORHOOD_CLUSTER", "VOTING_PRECINCT"]]

print(df_location_geog.info())

# Dropping null values

df_location_geog_nonull = df_location_geog.dropna()

print(df_location_geog_nonull.info())

print(df_location_geog_nonull.groupby(["BLOCK", "XBLOCK", "YBLOCK"]).size())

# Create a dictionary mapping (XBLOCK, YBLOCK) to BLOCK
block_mapping = dict(zip(zip(df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"]), df_location_geog_nonull["BLOCK"]))

# Define a custom function to fill in the missing BLOCK values
def fill_block(row):
    if pd.isna(row["BLOCK"]):  # If block is missing
        return block_mapping.get((row["XBLOCK"], row["YBLOCK"]), row["BLOCK"])
    return row["BLOCK"]

# Apply the function to the 'block' column
df_combine["BLOCK"] = df_combine.apply(fill_block, axis=1)

# Create a dictionary mapping (XBLOCK, YBLOCK) to WARD
Ward_mapping = dict(zip(zip(df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"]), df_location_geog_nonull["WARD"]))

# Define a custom function to fill in the missing WARD values
def fill_ward(row):
    if pd.isna(row["WARD"]):  # If block is missing
        return Ward_mapping.get((row["XBLOCK"], row["YBLOCK"]), row["WARD"])
    return row["WARD"]

# Apply the function to the 'WARD' column
df_combine["WARD"] = df_combine.apply(fill_ward, axis=1)

# Create a dictionary mapping (XBLOCK, YBLOCK) to ANC
ANC_mapping = dict(zip(zip(df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"]), df_location_geog_nonull["ANC"]))

# Define a custom function to fill in the missing ANC values
def fill_anc(row):
    if pd.isna(row["ANC"]):  # If ANC is missing
        return ANC_mapping.get((row["XBLOCK"], row["YBLOCK"]), row["ANC"])
    return row["ANC"]

# Apply the function to the 'ANC' column
df_combine["ANC"] = df_combine.apply(fill_anc, axis=1)

# Create a dictionary mapping (BLOCK, XBLOCK, YBLOCK, WARD, ANC) to DISTRICT
DISTRICT_mapping = dict(zip(zip(df_location_geog_nonull["BLOCK"], df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"], df_location_geog_nonull["WARD"], df_location_geog_nonull["ANC"]), df_location_geog_nonull["DISTRICT"]))

# Define a custom function to fill in the missing DISTRICT values
def fill_district(row):
    if pd.isna(row["DISTRICT"]):  # If DISTRICT is missing
        return DISTRICT_mapping.get((row["BLOCK"], row["XBLOCK"], row["YBLOCK"], row["WARD"], row["ANC"]), row["DISTRICT"])
    return row["DISTRICT"]

# Apply the function to the 'DISTRICT' column
df_combine["DISTRICT"] = df_combine.apply(fill_district, axis=1)

# Create a dictionary mapping (BLOCK, XBLOCK, YBLOCK, WARD, ANC, DISTRICT) to PSA
PSA_mapping = dict(zip(zip(df_location_geog_nonull["BLOCK"], df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"], df_location_geog_nonull["WARD"], df_location_geog_nonull["ANC"], df_location_geog_nonull["DISTRICT"]), df_location_geog_nonull["PSA"]))

# Define a custom function to fill in the missing PSA values
def fill_psa(row):
    if pd.isna(row["PSA"]):  # If PSA is missing
        return PSA_mapping.get((row["BLOCK"], row["XBLOCK"], row["YBLOCK"], row["WARD"], row["ANC"], row["DISTRICT"]), row["PSA"])
    return row["PSA"]

# Apply the function to the 'PSA' column
df_combine["PSA"] = df_combine.apply(fill_psa, axis=1)

# Create a dictionary mapping (BLOCK, XBLOCK, YBLOCK, WARD, ANC, DISTRICT, PSA) to NEIGHBORHOOD_CLUSTER
NEIGHBORHOOD_CLUSTER_mapping = dict(zip(zip(df_location_geog_nonull["BLOCK"], df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"], df_location_geog_nonull["WARD"], df_location_geog_nonull["ANC"], df_location_geog_nonull["DISTRICT"], df_location_geog_nonull["PSA"]), df_location_geog_nonull["NEIGHBORHOOD_CLUSTER"]))

# Define a custom function to fill in the missing NEIGHBORHOOD_CLUSTER values
def fill_ward(row):
    if pd.isna(row["NEIGHBORHOOD_CLUSTER"]):  # If NEIGHBORHOOD_CLUSTER is missing
        return NEIGHBORHOOD_CLUSTER_mapping.get((row["BLOCK"], row["XBLOCK"], row["YBLOCK"], row["WARD"], row["ANC"], row["DISTRICT"], row["PSA"]), row["NEIGHBORHOOD_CLUSTER"])
    return row["NEIGHBORHOOD_CLUSTER"]

# Apply the function to the 'NEIGHBORHOOD_CLUSTER' column
df_combine["NEIGHBORHOOD_CLUSTER"] = df_combine.apply(fill_ward, axis=1)

# Create a dictionary mapping (BLOCK, XBLOCK, YBLOCK, WARD, ANC, DISTRICT, PSA, NEIGHBORHOOD_CLUSTER) to VOTING_PRECINCT
VOTING_PRECINCT_mapping = dict(zip(zip(df_location_geog_nonull["BLOCK"], df_location_geog_nonull["XBLOCK"], df_location_geog_nonull["YBLOCK"], df_location_geog_nonull["WARD"], df_location_geog_nonull["ANC"], df_location_geog_nonull["DISTRICT"], df_location_geog_nonull["PSA"], df_location_geog_nonull["NEIGHBORHOOD_CLUSTER"]), df_location_geog_nonull["VOTING_PRECINCT"]))

# Define a custom function to fill in the missing VOTING_PRECINCT values
def fill_ward(row):
    if pd.isna(row["VOTING_PRECINCT"]):  # If VOTING_PRECINCT is missing
        return VOTING_PRECINCT_mapping.get((row["BLOCK"], row["XBLOCK"], row["YBLOCK"], row["WARD"], row["ANC"], row["DISTRICT"], row["PSA"], row["NEIGHBORHOOD_CLUSTER"]), row["VOTING_PRECINCT"])
    return row["VOTING_PRECINCT"]

# Apply the function to the 'VOTING_PRECINCT' column
df_combine["VOTING_PRECINCT"] = df_combine.apply(fill_ward, axis=1)

print(df_combine.info())

# Dropping columns that we do not need

df_combine.drop("X", axis=1, inplace=True)
df_combine.drop("Y", axis=1, inplace=True)
df_combine.drop("CCN", axis=1, inplace=True)
df_combine.drop("XBLOCK", axis=1, inplace=True)
df_combine.drop("YBLOCK", axis=1, inplace=True)
df_combine.drop("NEIGHBORHOOD_CLUSTER", axis=1, inplace=True)
df_combine.drop("BLOCK_GROUP", axis=1, inplace=True)
df_combine.drop("CENSUS_TRACT", axis=1, inplace=True)
df_combine.drop("BID", axis=1, inplace=True)
df_combine.drop("START_DATE", axis=1, inplace=True)
df_combine.drop("END_DATE", axis=1, inplace=True)
df_combine.drop("OBJECTID", axis=1, inplace=True)
df_combine.drop("OCTO_RECORD_ID", axis=1, inplace=True)

print(df_combine.info())

# dropping rows with null values

df_final = df_combine.dropna()

print(df_final.info())

print(df_final["REPORT_DAT"].head(10))

# Splitting REPORT_DAT into Year, Month, Day, Hour and Minute

df_final["YEAR"] = df_final["REPORT_DAT"].str[0:4]
df_final["MONTH"] = df_final["REPORT_DAT"].str[5:7]
df_final["DAY"] = df_final["REPORT_DAT"].str[8:10]
df_final["HOUR"] = df_final["REPORT_DAT"].str[11:13]
df_final["MINUTE"] = df_final["REPORT_DAT"].str[14:16]

print(df_final.info())

df_final.drop("REPORT_DAT", axis=1, inplace=True)

# Rearranging Columns

df_final = df_final[["YEAR", "MONTH", "DAY", "HOUR", "MINUTE", "SHIFT", "METHOD", "OFFENSE", "BLOCK", "WARD", "ANC", "DISTRICT", "PSA", "VOTING_PRECINCT", "LATITUDE", "LONGITUDE"]]

print(df_final.info())

df_final.head(10)

# Finalizing data types for each column

df_final["YEAR"] = df_final["YEAR"].astype(int)
df_final["MONTH"] = df_final["MONTH"].astype(int)
df_final["DAY"] = df_final["DAY"].astype(int)
df_final["HOUR"] = df_final["HOUR"].astype(int)
df_final["MINUTE"] = df_final["MINUTE"].astype(int)
df_final["SHIFT"] = df_final["SHIFT"].astype("category")
df_final["METHOD"] = df_final["METHOD"].astype("category")
df_final["OFFENSE"] = df_final["OFFENSE"].astype("category")
df_final["BLOCK"] = df_final["BLOCK"].astype(str)
df_final["WARD"] = df_final["WARD"].astype(int)
df_final["ANC"] = df_final["ANC"].astype("category")
df_final["DISTRICT"] = df_final["DISTRICT"].astype(int)
df_final["PSA"] = df_final["PSA"].astype(int)
df_final["VOTING_PRECINCT"] = df_final["VOTING_PRECINCT"].astype("category")

# Merging 2 categories in offense - THEFT/OTHER and THEFT F/AUTO to THEFT

df_final["OFFENSE"] = df_final["OFFENSE"].replace({"THEFT/OTHER": "THEFT", "THEFT F/AUTO": "THEFT"})

df_final["OFFENSE"].value_counts()

print(df_final.info())

# Saving the dataset into a csv file

df_final.to_csv('combined_data.csv', index=False)