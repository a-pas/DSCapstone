{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXKJif9eB0RV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024 = pd.read_csv(\"/content/combined_data_2024.csv\")\n",
        "#df_2023 = pd.read_csv(\"/content/combined_data.csv\")"
      ],
      "metadata": {
        "id": "2bjuTQiZB9WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfblyaBGB94X",
        "outputId": "ad9b6ddf-5128-48ac-a7be-009fc4f4442e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 554119 entries, 0 to 554118\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   YEAR             554119 non-null  int64  \n",
            " 1   MONTH            554119 non-null  int64  \n",
            " 2   DAY              554119 non-null  int64  \n",
            " 3   HOUR             554119 non-null  int64  \n",
            " 4   MINUTE           554119 non-null  int64  \n",
            " 5   SHIFT            554119 non-null  object \n",
            " 6   METHOD           554119 non-null  object \n",
            " 7   OFFENSE          554119 non-null  object \n",
            " 8   BLOCK            554119 non-null  object \n",
            " 9   WARD             554119 non-null  int64  \n",
            " 10  ANC              554119 non-null  object \n",
            " 11  DISTRICT         554119 non-null  int64  \n",
            " 12  PSA              554119 non-null  int64  \n",
            " 13  VOTING_PRECINCT  554119 non-null  object \n",
            " 14  LATITUDE         554119 non-null  float64\n",
            " 15  LONGITUDE        554119 non-null  float64\n",
            "dtypes: float64(2), int64(8), object(6)\n",
            "memory usage: 67.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_2023.info()"
      ],
      "metadata": {
        "id": "2Ahn8Oz-CBd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024[\"OFFENSE\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfjYRkgJEC5S",
        "outputId": "afafeab6-f395-4e0c-c72f-9a58a10ddb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['THEFT', 'ASSAULT W/DANGEROUS WEAPON', 'ROBBERY',\n",
              "       'MOTOR VEHICLE THEFT', 'BURGLARY', 'ARSON', 'HOMICIDE',\n",
              "       'SEX ABUSE'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024[\"OFFENSE\"] = df_2024[\"OFFENSE\"].replace({\"ROBBERY\": \"THEFT\", \"BURGLARY\": \"THEFT\"})"
      ],
      "metadata": {
        "id": "m67cIWBpH_MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2024[\"OFFENSE\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNTimZzxIwmD",
        "outputId": "8238987e-c4cb-4de5-abbc-97de3474d5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['THEFT', 'ASSAULT W/DANGEROUS WEAPON', 'MOTOR VEHICLE THEFT',\n",
              "       'ARSON', 'HOMICIDE', 'SEX ABUSE'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "x_independent = df_2024.drop(columns=['OFFENSE', 'BLOCK'])  # Drop the target variable and DAY column\n",
        "y_dependent = df_2024['OFFENSE']  # Target variable\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_dependent)\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['SHIFT', 'METHOD', 'ANC', 'VOTING_PRECINCT']  # Categorical features\n",
        "numerical_cols = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'WARD', 'DISTRICT', 'PSA', 'LATITUDE', 'LONGITUDE']  # Numerical features\n",
        "\n",
        "# One-Hot Encode Categorical Variables using pd.get_dummies()\n",
        "# drop_first=True avoids dummy variable trap\n",
        "X_encoded = pd.get_dummies(x_independent, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Combine the encoded categorical columns with numerical columns (already included in X_encoded)\n",
        "\n",
        "# Split the data: 90% training, 10% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.10, random_state=42)\n",
        "\n",
        "# Print shapes of the training and test sets\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6pBWOQ_JBUX",
        "outputId": "7c18a844-1b49-4dde-b294-bd988aa26b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (498707, 203), X_test shape: (55412, 203)\n",
            "y_train shape: (498707,), y_test shape: (55412,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "yoa1OPh7JRTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Create and configure the XGBoost model\n",
        "model_xgb = XGBClassifier(\n",
        "    use_label_encoder=False,         # Disable the label encoder warning\n",
        "    eval_metric='mlogloss',         # Set evaluation metric for multi-class classification\n",
        "    random_state=42,                # For reproducibility\n",
        "    n_estimators=500,               # Increase the number of boosting rounds\n",
        "    learning_rate=0.05,             # Lower learning rate\n",
        "    max_depth=6,                    # Adjust max depth (experiment with values like 3, 5, or 7)\n",
        "    min_child_weight=1,             # Minimum child weight to prevent overfitting\n",
        "    subsample=0.8,                  # Use 80% of the training data for each tree\n",
        "    colsample_bytree=0.8,           # Use 80% of features for each tree\n",
        "    scale_pos_weight=None,            # Set this if you have imbalanced classes\n",
        "    tree_method='gpu_hist'\n",
        ")\n",
        "# Fit the model\n",
        "model_xgb.fit(X_train, y_train, verbose=True)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mkH0qzsJZn8",
        "outputId": "ba0b503d-2aa3-4c21-cf86-eb373bdf263a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:48:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:49:02] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.70      0.43      0.53      3276\n",
            "           2       0.93      0.94      0.93       252\n",
            "           3       0.44      0.00      0.01      5945\n",
            "           4       0.00      0.00      0.00       387\n",
            "           5       0.85      0.99      0.91     45514\n",
            "\n",
            "    accuracy                           0.84     55412\n",
            "   macro avg       0.49      0.39      0.40     55412\n",
            "weighted avg       0.79      0.84      0.78     55412\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "# Fit the model\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_lr.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi5t7zpSJdFy",
        "outputId": "acd39fb1-3d3e-43b6-9943-a0c829b731c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.63      0.19      0.30      3276\n",
            "           2       0.00      0.00      0.00       252\n",
            "           3       0.00      0.00      0.00      5945\n",
            "           4       0.00      0.00      0.00       387\n",
            "           5       0.83      0.99      0.91     45514\n",
            "\n",
            "    accuracy                           0.83     55412\n",
            "   macro avg       0.24      0.20      0.20     55412\n",
            "weighted avg       0.72      0.83      0.76     55412\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "model_lgb = lgb.LGBMClassifier()\n",
        "# Fit the model\n",
        "model_lgb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_lgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR7hOp4cJgHo",
        "outputId": "6b8a5794-8397-4ca8-9b7b-71493f680360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031415 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1118\n",
            "[LightGBM] [Info] Number of data points in the train set: 498707, number of used features: 203\n",
            "[LightGBM] [Info] Start training from score -7.290828\n",
            "[LightGBM] [Info] Start training from score -2.792949\n",
            "[LightGBM] [Info] Start training from score -5.349973\n",
            "[LightGBM] [Info] Start training from score -2.239277\n",
            "[LightGBM] [Info] Start training from score -4.989126\n",
            "[LightGBM] [Info] Start training from score -0.198472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.69      0.41      0.52      3276\n",
            "           2       0.81      0.88      0.84       252\n",
            "           3       0.20      0.00      0.00      5945\n",
            "           4       0.11      0.01      0.01       387\n",
            "           5       0.84      0.98      0.91     45514\n",
            "\n",
            "    accuracy                           0.84     55412\n",
            "   macro avg       0.44      0.38      0.38     55412\n",
            "weighted avg       0.76      0.84      0.78     55412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV96TfYiJpRp",
        "outputId": "ac0e3797-0371-49f9-b032-9c2b44399d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model_cbc = CatBoostClassifier(silent=True, random_state=42)\n",
        "# Fit the model\n",
        "model_cbc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_cbc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYHzAYlHJgnr",
        "outputId": "2d715101-7126-4c1e-e5bf-7a8fb952417f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.71      0.43      0.53      3276\n",
            "           2       0.93      0.93      0.93       252\n",
            "           3       0.52      0.01      0.02      5945\n",
            "           4       0.00      0.00      0.00       387\n",
            "           5       0.85      0.99      0.91     45514\n",
            "\n",
            "    accuracy                           0.84     55412\n",
            "   macro avg       0.50      0.39      0.40     55412\n",
            "weighted avg       0.80      0.84      0.79     55412\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model_knn = KNeighborsClassifier()\n",
        "# Fit the model\n",
        "model_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lVkdrL_CJj7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf2c18e-986c-4a55-aca0-6dbfdeb63baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.20      0.06      0.10      3276\n",
            "           2       0.60      0.69      0.64       252\n",
            "           3       0.20      0.07      0.10      5945\n",
            "           4       0.00      0.00      0.00       387\n",
            "           5       0.83      0.95      0.89     45514\n",
            "\n",
            "    accuracy                           0.80     55412\n",
            "   macro avg       0.30      0.30      0.29     55412\n",
            "weighted avg       0.72      0.80      0.75     55412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model_naivebayes = GaussianNB()\n",
        "# Fit the model\n",
        "model_naivebayes.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_naivebayes.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXrMvGi8efeW",
        "outputId": "57622947-c522-4df7-9412-39a5f8e4b519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.84      0.00        38\n",
            "           1       0.31      0.43      0.36      3276\n",
            "           2       0.57      0.75      0.65       252\n",
            "           3       0.17      0.11      0.13      5945\n",
            "           4       0.01      0.05      0.02       387\n",
            "           5       0.91      0.26      0.40     45514\n",
            "\n",
            "    accuracy                           0.25     55412\n",
            "   macro avg       0.33      0.41      0.26     55412\n",
            "weighted avg       0.79      0.25      0.37     55412\n",
            "\n"
          ]
        }
      ]
    }
  ]
}