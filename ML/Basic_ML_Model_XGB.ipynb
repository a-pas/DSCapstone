{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SSxIP-bFZmm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/combined_data_2024.csv\")"
      ],
      "metadata": {
        "id": "jFsMe1u_5On1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "QPM_qa0659Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90405cd-8bfc-4ed4-8ffe-329eac64603d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 554119 entries, 0 to 554118\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   YEAR             554119 non-null  int64  \n",
            " 1   MONTH            554119 non-null  int64  \n",
            " 2   DAY              554119 non-null  int64  \n",
            " 3   HOUR             554119 non-null  int64  \n",
            " 4   MINUTE           554119 non-null  int64  \n",
            " 5   SHIFT            554119 non-null  object \n",
            " 6   METHOD           554119 non-null  object \n",
            " 7   OFFENSE          554119 non-null  object \n",
            " 8   BLOCK            554119 non-null  object \n",
            " 9   WARD             554119 non-null  int64  \n",
            " 10  ANC              554119 non-null  object \n",
            " 11  DISTRICT         554119 non-null  int64  \n",
            " 12  PSA              554119 non-null  int64  \n",
            " 13  VOTING_PRECINCT  554119 non-null  object \n",
            " 14  LATITUDE         554119 non-null  float64\n",
            " 15  LONGITUDE        554119 non-null  float64\n",
            "dtypes: float64(2), int64(8), object(6)\n",
            "memory usage: 67.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-Square Test Between Categorical Variables\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Assuming df is your DataFrame and you want to test categorical columns with 'OFFENSE'\n",
        "\n",
        "# List of categorical columns to test against 'OFFENSE'\n",
        "categorical_cols = ['SHIFT', 'METHOD', 'BLOCK', 'ANC', 'VOTING_PRECINCT']\n",
        "\n",
        "# Perform Chi-Square test for each categorical column with the target categorical column 'OFFENSE'\n",
        "for col in categorical_cols:\n",
        "    # Create a contingency table\n",
        "    contingency_table = pd.crosstab(df1[col], df1['OFFENSE'])\n",
        "\n",
        "    # Perform Chi-Square test\n",
        "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "    # Output the result\n",
        "    print(f\"Chi-Square Test for {col} and OFFENSE:\")\n",
        "    print(f\"Chi2 Statistic = {chi2}, p-value = {p}\")\n",
        "    print(f\"Degrees of Freedom = {dof}\\n\")\n"
      ],
      "metadata": {
        "id": "boa3xFOCAJ_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9606606b-01c1-4a97-be8b-874b4e4b4cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Test for SHIFT and OFFENSE:\n",
            "Chi2 Statistic = 38444.32607351279, p-value = 0.0\n",
            "Degrees of Freedom = 14\n",
            "\n",
            "Chi-Square Test for METHOD and OFFENSE:\n",
            "Chi2 Statistic = 352127.39755209006, p-value = 0.0\n",
            "Degrees of Freedom = 14\n",
            "\n",
            "Chi-Square Test for BLOCK and OFFENSE:\n",
            "Chi2 Statistic = 303698.86367193045, p-value = 0.0\n",
            "Degrees of Freedom = 139944\n",
            "\n",
            "Chi-Square Test for ANC and OFFENSE:\n",
            "Chi2 Statistic = 60861.32622106574, p-value = 0.0\n",
            "Degrees of Freedom = 322\n",
            "\n",
            "Chi-Square Test for VOTING_PRECINCT and OFFENSE:\n",
            "Chi2 Statistic = 70108.34340219847, p-value = 0.0\n",
            "Degrees of Freedom = 1001\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "x_independent = df1.drop(columns=['OFFENSE', 'BLOCK'])  # Drop the target variable and DAY column\n",
        "y_dependent = df1['OFFENSE']  # Target variable\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_dependent)\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['SHIFT', 'METHOD', 'ANC', 'VOTING_PRECINCT']  # Categorical features\n",
        "numerical_cols = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'WARD', 'DISTRICT', 'PSA', 'LATITUDE', 'LONGITUDE']  # Numerical features\n",
        "\n",
        "# One-Hot Encode Categorical Variables using pd.get_dummies()\n",
        "# drop_first=True avoids dummy variable trap\n",
        "X_encoded = pd.get_dummies(x_independent, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Combine the encoded categorical columns with numerical columns (already included in X_encoded)\n",
        "\n",
        "# Split the data: 90% training, 10% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.05, random_state=42)\n",
        "\n",
        "# Print shapes of the training and test sets\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "582P21698phD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9760c535-14b2-4b14-cb1d-e6e9ef5cb7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (526413, 203), X_test shape: (27706, 203)\n",
            "y_train shape: (526413,), y_test shape: (27706,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        " # Till here all then svc"
      ],
      "metadata": {
        "id": "d785Sw_IwKca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Create and configure the XGBoost model\n",
        "model_xgb = XGBClassifier(\n",
        "    use_label_encoder=False,         # Disable the label encoder warning\n",
        "    eval_metric='mlogloss',         # Set evaluation metric for multi-class classification\n",
        "    random_state=42,                # For reproducibility\n",
        "    n_estimators=500,               # Increase the number of boosting rounds\n",
        "    learning_rate=0.05,             # Lower learning rate\n",
        "    max_depth=6,                    # Adjust max depth (experiment with values like 3, 5, or 7)\n",
        "    min_child_weight=1,             # Minimum child weight to prevent overfitting\n",
        "    subsample=0.8,                  # Use 80% of the training data for each tree\n",
        "    colsample_bytree=0.8,           # Use 80% of features for each tree\n",
        "    scale_pos_weight=None,            # Set this if you have imbalanced classes\n",
        "    tree_method='gpu_hist'\n",
        ")\n",
        "# Fit the model\n",
        "model_xgb.fit(X_train, y_train, verbose=True)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "c_nj4rmd9MjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a0b1a1-9563-42df-ca0f-9604cfc1e0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:39:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:39:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:40:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        17\n",
            "           1       0.70      0.43      0.53      1674\n",
            "           2       0.44      0.03      0.06      1987\n",
            "           3       0.94      0.93      0.94       140\n",
            "           4       0.39      0.02      0.05      2936\n",
            "           5       0.64      0.37      0.47      2518\n",
            "           6       0.00      0.00      0.00       170\n",
            "           7       0.73      0.99      0.84     18264\n",
            "\n",
            "    accuracy                           0.72     27706\n",
            "   macro avg       0.48      0.35      0.36     27706\n",
            "weighted avg       0.66      0.72      0.64     27706\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "# Fit the model\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_lr.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cywUXpomXZRY",
        "outputId": "80301240-ee96-46f0-a15b-34fc1897d70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        17\n",
            "           1       1.00      0.00      0.01      1674\n",
            "           2       0.00      0.00      0.00      1987\n",
            "           3       0.36      0.29      0.32       140\n",
            "           4       0.00      0.00      0.00      2936\n",
            "           5       0.41      0.03      0.05      2518\n",
            "           6       0.00      0.00      0.00       170\n",
            "           7       0.67      1.00      0.80     18264\n",
            "\n",
            "    accuracy                           0.66     27706\n",
            "   macro avg       0.30      0.16      0.15     27706\n",
            "weighted avg       0.54      0.66      0.53     27706\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_svc = SVC(random_state=42)\n",
        "# Fit the model\n",
        "model_svc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_svc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "e_404-nBXeDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model_knn = KNeighborsClassifier()\n",
        "# Fit the model\n",
        "model_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exrot7cyXfif",
        "outputId": "6c17a258-8e6b-4cae-afef-320a5edcd939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        17\n",
            "           1       0.19      0.12      0.15      1674\n",
            "           2       0.14      0.08      0.10      1987\n",
            "           3       0.61      0.71      0.66       140\n",
            "           4       0.19      0.11      0.14      2936\n",
            "           5       0.21      0.12      0.15      2518\n",
            "           6       0.06      0.01      0.01       170\n",
            "           7       0.71      0.86      0.78     18264\n",
            "\n",
            "    accuracy                           0.61     27706\n",
            "   macro avg       0.26      0.25      0.25     27706\n",
            "weighted avg       0.53      0.61      0.56     27706\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model_naivebayes = GaussianNB()\n",
        "# Fit the model\n",
        "model_naivebayes.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_naivebayes.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGNirQUrXhXD",
        "outputId": "ffee5f77-75e7-46e7-b9ad-5de804a9980b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.76      0.00        17\n",
            "           1       0.44      0.39      0.41      1674\n",
            "           2       0.10      0.03      0.04      1987\n",
            "           3       0.63      0.73      0.68       140\n",
            "           4       0.17      0.08      0.11      2936\n",
            "           5       0.26      0.17      0.20      2518\n",
            "           6       0.01      0.04      0.02       170\n",
            "           7       0.82      0.25      0.39     18264\n",
            "\n",
            "    accuracy                           0.22     27706\n",
            "   macro avg       0.30      0.31      0.23     27706\n",
            "weighted avg       0.62      0.22      0.32     27706\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "model_lgb = lgb.LGBMClassifier()\n",
        "# Fit the model\n",
        "model_lgb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_lgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSJmmSkVXigj",
        "outputId": "bd80c484-ca29-4a87-8a42-5f0c5533bd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057041 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1118\n",
            "[LightGBM] [Info] Number of data points in the train set: 526413, number of used features: 203\n",
            "[LightGBM] [Info] Start training from score -7.284963\n",
            "[LightGBM] [Info] Start training from score -2.795891\n",
            "[LightGBM] [Info] Start training from score -2.635604\n",
            "[LightGBM] [Info] Start training from score -5.357828\n",
            "[LightGBM] [Info] Start training from score -2.238255\n",
            "[LightGBM] [Info] Start training from score -2.386793\n",
            "[LightGBM] [Info] Start training from score -4.981271\n",
            "[LightGBM] [Info] Start training from score -0.420934\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        17\n",
            "           1       0.69      0.41      0.52      1674\n",
            "           2       0.43      0.03      0.05      1987\n",
            "           3       0.77      0.88      0.82       140\n",
            "           4       0.29      0.01      0.03      2936\n",
            "           5       0.62      0.37      0.46      2518\n",
            "           6       0.17      0.01      0.01       170\n",
            "           7       0.73      0.99      0.84     18264\n",
            "\n",
            "    accuracy                           0.72     27706\n",
            "   macro avg       0.46      0.34      0.34     27706\n",
            "weighted avg       0.65      0.72      0.64     27706\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model_cbc = CatBoostClassifier(silent=True, random_state=42)\n",
        "# Fit the model\n",
        "model_cbc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_cbc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JBimpC8Xjbn",
        "outputId": "ee64d1b2-1268-4e7f-a271-5eaa66658b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        17\n",
            "           1       0.71      0.44      0.54      1674\n",
            "           2       0.45      0.05      0.08      1987\n",
            "           3       0.93      0.94      0.93       140\n",
            "           4       0.37      0.03      0.06      2936\n",
            "           5       0.64      0.37      0.47      2518\n",
            "           6       0.00      0.00      0.00       170\n",
            "           7       0.73      0.99      0.84     18264\n",
            "\n",
            "    accuracy                           0.72     27706\n",
            "   macro avg       0.48      0.35      0.37     27706\n",
            "weighted avg       0.66      0.72      0.65     27706\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, tree_method='gpu_hist')\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 400, 600, 800, 1000],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [6, 8, 10],\n",
        "    'min_child_weight': [1, 3, 5, 7, 9],\n",
        "    'subsample': [0.5, 0.6, 0.7],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}"
      ],
      "metadata": {
        "id": "7kZ8C17vyD0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement GridSearchCV\n",
        "grid_search_accuracy = GridSearchCV(estimator=model,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',  # You can also use 'f1', 'roc_auc', etc.\n",
        "                           cv=5,                # 5-fold cross-validation\n",
        "                           verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "grid_search_accuracy.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best parameters found: \", grid_search_accuracy.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}%\".format(grid_search_accuracy.best_score_ * 100))"
      ],
      "metadata": {
        "id": "zk2qrseh2fSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement GridSearchCV for F1 Score\n",
        "grid_search_f1 = GridSearchCV(estimator=model,\n",
        "                               param_grid=param_grid,\n",
        "                               scoring='f1_weighted',  # Use F1 Score as the scoring metric\n",
        "                               cv=5,                    # 5-fold cross-validation\n",
        "                               verbose=1)\n",
        "\n",
        "# Fit the model for F1 Score\n",
        "grid_search_f1.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for F1 Score\n",
        "print(\"Best parameters found (F1 Score): \", grid_search_f1.best_params_)\n",
        "print(\"Best F1 score: {:.2f}%\".format(grid_search_f1.best_score_ * 100))"
      ],
      "metadata": {
        "id": "vy9xA7k72CKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement GridSearchCV for Recall\n",
        "grid_search_recall = GridSearchCV(estimator=model,\n",
        "                                   param_grid=param_grid,\n",
        "                                   scoring='recall_weighted',  # Use Recall as the scoring metric\n",
        "                                   cv=5,                        # 5-fold cross-validation\n",
        "                                   verbose=1)\n",
        "\n",
        "# Fit the model for Recall\n",
        "grid_search_recall.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score for Recall\n",
        "print(\"Best parameters found (Recall): \", grid_search_recall.best_params_)\n",
        "print(\"Best Recall score: {:.2f}%\".format(grid_search_recall.best_score_ * 100))"
      ],
      "metadata": {
        "id": "AOUn-seV2dlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}